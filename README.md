# è¿™æ˜¯ä¸€ä¸ªç„Šæ¥chatgpt/gpt3å’Œvitsçš„åç«¯apiç¨‹åº
ç”¨apiå¯åŠ¨çš„ä¸»è¦ç›®çš„æ˜¯æ­å»ºloveliveçš„èŠå¤©ç½‘ç«™ï¼Œå…¶å®16å·å°±å·²ç»æŠŠè¿™ä¸ªé¡¹ç›®æå¥½äº†ã€‚å› ä¸ºloveliveä¸åƒé‚¦é‚¦å’Œå°‘æ­Œé‚£æ ·æœ‰live2dæ¨¡å‹ï¼Œæ‰¾å„ç§æ–¹æ¡ˆæç½®äº†ä¸€å‘¨å¤šã€‚çœ‹äº†åˆ«çš„upçš„è§†é¢‘åå‘ç°å¤§å®¶å¯¹è¿™ç§å½¢å¼çš„çƒ­æƒ…å¾ˆé«˜ï¼Œå°±æŠŠè¿™ä¸ªæ”¾åœ¨æ–‡ä»¶å¤¹é‡Œåƒç°çš„é¡¹ç›®æ‹¿å‡ºæ¥äº†ã€‚
å‚è€ƒç”¨é“¾æ¥http://43.159.36.6:8080/
é¡¹ç›®åœ°å€https://drive.google.com/drive/folders/1vtootVMQ7wTOQwd15nJe6akzJUYNOw4d
è§£å‹live2d_chat-0.6(gpt3+chatgpt).zipï¼Œ
è¿è¡Œæ¸¸æˆç¨‹åºï¼Œ
å»ºè®®ç”¨renpyä¿®æ”¹æ¸¸æˆç¨‹åºï¼Œå†…ç½®é…ç½®æµç¨‹ï¼Œè‡ªå®šä¹‰ä½ çš„live2dæ¨¡å‹å’Œäº¤äº’æ–¹å¼ã€‚

## How to launch API in your windows or server
(Suggestion) Python == 3.8/3.7
## Clone a VITS repository or iSTFT-VITS repository
```sh
git clone https://github.com/CjangCjengh/vits.git
#git clone https://github.com/innnky/MB-iSTFT-VITS
```
## Get the model and config
- See https://github.com/CjangCjengh/TTSModels or other repositorise in Github or huggingface
## Adding cleaners&inference_api.py to your project
- Noticing "text_cleaners" in config.json
- Edit 'text'dictionary in the VITS or iSTFT-VITS
- Remove unnecessary imports from text/cleaners.py
- The path of inference_api.py should be like path/to/vits/inference_api.py
- If you want to launch this project in your server, it is recommended to use iSTFT-VITS for tts: path/to/MB-iSTFT-VITS/inference_api.py
## Install requirements of vits enviornments
```sh
cd vits
#cd MB-iSTFT-VITS
pip install -r requirements.txt
```
## Build Monotonic Alignment Search and run preprocessing
```sh
# Cython-version Monotonoic Alignment Search
cd monotonic_align
mkdir monotonic_align
python setup.py build_ext --inplace
cd vits
#cd MB-iSTFT-VITS
```
## Install requirements for using GPT3/CHATGPT in python
```sh
pip install pydub 
pip install openai
#Not recommended due to demanding requirements
#pip install pyChatGPT
```
## Editing the path of configuration file in inference_api.py
```sh
line26:#è®¾å®šå­˜å‚¨å„ç§æ•°æ®çš„ç›®å½•ï¼Œæ–¹ä¾¿æŸ¥çœ‹ï¼Œé»˜è®¤C:/project_file
line27:current_work_dir = os.path.dirname(__file__)
line28:weight_path = os.path.join(current_work_dir, '/project_file/')
line34:hps_ms = utils.get_hparams_from_file("path/to/config.json")
line43:_ = utils.load_checkpoint("path/to/checkpoint.pth", net_g_ms, None)
```
## For CPU inference in server or those who do not have cuda installed
```sh
#change this line to dev = torch.device("cpu")
line32:dev = torch.device("cuda:0")
```
## launch
```sh
python inference_api.py
```
## What to do next?
As you can see in the temminal
```sh
 * Serving Flask app 'inference_api'
 * Debug mode: on
INFO:werkzeug: WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://10.0.0.14:8080
INFO:werkzeug: Press CTRL+C to quit
```
Which means you can try it in the game now
## Why using api?
ä¸ä¼šçœŸæœ‰äººæƒ³æ¯æ¬¡éƒ½è¦å¯åŠ¨ä¸€å †ç¨‹åºï¼Œé…ç½®ä¸ªåŠå¤©ï¼Œåƒç”µè„‘ä¸€å¤§åŠå†…å­˜å’Œæ˜¾å­˜æ¥è·Ÿçº¸ç‰‡äººèŠå¤©å§ï¼Œåæ­£æˆ‘è°ƒè¯•å®Œä¹‹åè‚¯å®šä¸ä¼šï¼Œ20å—ä¸€ä¸ªæœˆçš„æœåŠ¡å™¨ä¸é¦™å—ï¼Ÿ
## Real usage for api
Building chatroom on my website. Now preparing the live2d models.
## Why not chatgpt?
You can edit it in the inference_api.py
```sh
line143:#CHATGPTæŠ“å–
line144:#session_token = 'å‚è€ƒhttps://www.youtube.com/watch?v=TdNSj_qgdFk'
line145:#api = ChatGPT(session_token)
#Delate the comment in line200 and line233
```
If you want to chat with it indiscriminately as if it is your waifu, the company will stop you lol.
## What to do with game?
Official website of RenPy https://www.renpy.org/
You can follow the instructions and beautify your game, can take my game given as a reference.

## æé€Ÿå…¥é—¨renpy
æŠ›å¼ƒé‚£äº›èŠ±é‡Œèƒ¡å“¨çš„è®¾ç½®ï¼Œåªç¼–è¾‘script.rpyã€‚äº¤äº’å¼live2dçš„æ ¸å¿ƒä»£ç 
```sh
#å®šä¹‰è§’è‰²,è¿™ä¸ªç±»å°†ä¼šç»§æ‰¿æˆ‘ä»¬éœ€è¦çš„live2dæ¨¡å‹å’Œè¯­éŸ³æ–‡ä»¶è¿™äº›èŠ±é‡Œèƒ¡å“¨çš„ä¸œè¥¿
define Character1 = Character("Your_Character_Name")
#ä¸ºæ¸¸æˆé…ç½®live2dï¼Œä½ éœ€è¦åœ¨å®‰è£…renpyåå°†ä»live2då®˜ç½‘ä¸‹è½½çš„cublism for nativeå‹ç¼©åŒ…æ”¾åˆ°renpyçš„ç›®å½•ä¸‹ï¼Œä¹‹åç‚¹å¼€renpyæŒ‰ç…§æŒ‡ç¤ºè‡ªåŠ¨åŠ è½½ã€‚
define config.gl2 = True
#å¯¼å…¥live2dæ¨¡å‹,å¤§éƒ¨åˆ†live2dæ¨¡å‹çš„æ–‡ä»¶å¤¹åå­—å’Œmodel3æ–‡ä»¶çš„åå­—ç›¸åŒï¼Œå¯ä»¥ç›´æ¥å°†è·¯å¾„åè®¾ç½®ä¸ºæ–‡ä»¶å¤¹çš„åå­—ï¼Œä¿é™©èµ·è§ä¹Ÿå¯ç›´æ¥å¯¹åº”model3æ–‡ä»¶
image Character1 = Live2D("Path/to/your_model/your_model.model3.json", top=0.0, base=0.7, height=1.0,loop=True)
#ä¸€å®šè¦æœ‰ä¸€ä¸ª"å¼€å§‹"åœºæ™¯ï¼Œåœºæ™¯ç”¨labelæ ‡è®°ã€‚
label start:
#å¯¼å…¥èƒŒæ™¯å›¾ç‰‡ï¼Œåœ¨image å¤„è‡ªå®šä¹‰ï¼Œæ ¼å¼â€˜bg name.pngâ€™,ä¸­é—´è¦å¸¦ç©ºæ ¼å·ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆè¦è¿™æ ·è®¾å®š
    show bg name
    #åŠ è½½live2dåŠ¨ä½œï¼Œå‚è€ƒhttps://www.renpy.cn/doc/live2d.html
#live2dæ¨¡å‹éƒ½æœ‰è‡ªå·±çš„åŠ¨ä½œåï¼Œä½ å¯ä»¥åœ¨model3æ–‡ä»¶ä¸­æŸ¥çœ‹ï¼Œä¹Ÿå¯ä»¥è‡ªå·±ç”¨åŠ¨ä½œæ•æ‰å·¥å…·(steamé‡Œæœvtuber)è‡ªå®šä¹‰ã€‚
    show Character1 motion1
#renpyæœ‰ä¸¤ç§åŠ è½½pythonå‘½ä»¤çš„æ–¹å¼ï¼Œä¸€ç§æ˜¯"$ "+ä»£ç ï¼Œå¦å¤–ä¸€ç§æ˜¯"Python:"ï¼Œä¸‹ä¸€è¡Œç¼©è¿›åç¼–å†™ï¼Œè¿™é‡Œå…ˆç”¨"$ "
#å¯¼å…¥éœ€è¦çš„åº“
    $ import requests
    $ import os
    $ import threading 
#è¿™äº›å‚æ•°æ˜¯æˆ‘è®¤ä¸ºé€‚åˆåœ¨åº”ç”¨ç«¯è®¾å®šçš„
#spk_idæ˜¯vitsæ¨¡å‹ä¸­çš„äººç‰©idï¼Œvitså¤šäººæ¨¡å‹é€šè¿‡å˜åŒ–spk_idæ¥ä¿®æ”¹è¯´è¯äºº
    $ global spk_id
#your_nameæ˜¯ä¸ºäº†å¢åŠ ä»£å…¥æ„Ÿå’Œgpt3çš„chatbotèŠå¤©ç”¨çš„ï¼Œchatgptåˆ™ä¸éœ€è¦
    $ global your_name
#open_api_keyåˆ™æ˜¯æ¯ä¸ªäººç‰¹æœ‰çš„ï¼Œä½ ä¹Ÿå¯ä»¥ä»å®˜ç½‘ä¸Šå¤åˆ¶å¥½åç›´æ¥å­˜å‚¨åœ¨æ¸¸æˆä¸­
    $ global open_api_key
#web_baseå°±æ˜¯ç¨‹åºç”Ÿæˆçš„ç½‘å€ï¼Œæˆ‘è®¾å®šçš„ç¨‹åºéƒ½æ˜¯host/route_nameX?parameter1=[your_input1]&parameter2=[your_input2]......&parameter3=[your_input3]è¿™ç§å½¢å¼ï¼Œä½ ä¹Ÿå¯ä»¥æ”¹æˆè¡¨å•
    $ global web_base
#è¿™ä¸‰ä¸ªæ˜¯vitsç”¨åˆ°çš„å‚æ•°ï¼Œæ¨±èŠ±å¦¹è¯´ä¸­æ–‡è¿˜æ˜¯éœ€è¦ä»”ç»†è°ƒçš„ï¼Œä¸ç„¶å¾ˆéš¾å¬è¿›å»ã€‚ç‰¹åˆ«æ˜¯è½»é‡åŒ–æ¨¡å‹ï¼Œæ—¥æ–‡ä¹Ÿéœ€è¦()
    $ global noise_scale
    $ global noise_scale_w
    $ global speaking_speed
#jumpç›´æ¥åˆ‡æ¢è‡³ä¸‹ä¸€åœºæ™¯
    jump setting0
return

label setting0:
#renpyéœ€è¦åœ¨pythonå‘½ä»¤ä¸­ç”¨renpy.inputè·å–æ–‡æœ¬è¾“å…¥ï¼Œè¿™æ ·å°±å¯ä»¥ä¿®æ”¹å‚æ•°äº†ã€‚è°ƒè¯•åå¯ä»¥å°†è¿™äº›å‚æ•°å­˜å‚¨åœ¨æ¸¸æˆæ–‡ä»¶ä¸­ã€‚
    $ web_base = renpy.input("è¾“å…¥åç«¯apiçš„åœ°å€ï¼Œå¦‚æœ¬åœ°æ¨ç†ä¸º'http://127.0.0.1:8080'ï¼Œç»ˆç«¯è¿è¡Œinference_api.pyæ—¶æŸ¥çœ‹",length=100)
    $ open_api_key = renpy.input("å¡«å†™ä½ çš„API keys ç½‘å€ï¼šhttps://beta.openai.com/account/api-keys",length=1000)
    $ open_api_key = str(open_api_key)
    $ your_name = renpy.input("ä½ çš„åå­—ï¼š",length=10)
    $ noise_scale = renpy.input('å¡«å†™å™ªå£°å‚æ•°ï¼Œé»˜è®¤è¾“å…¥0.667',length=10)
    $ noise_scale_w = renpy.input('å¡«å†™å™ªå£°å‚æ•°åå·®ï¼Œé»˜è®¤è¾“å…¥0.8',length=10)
    $ noise_scale_0 = renpy.input('è¯­é€Ÿè®¾ç½®ï¼Œé»˜è®¤1',length=10)
    $ spk_id = int(renpy.input("å¯¹è¯è§’è‰²",length=10))
#rensheè¿™ä¸ªç©æ„æ˜¯ç”¨æ¥å’Œgpt3å¯¹è¯ç”¨çš„ï¼Œå®é™…ä¸Šæœ‰äº›å¤šä½™äº†ï¼Œchatgptåˆ™å®Œå…¨ä¸éœ€è¦ï¼Œç›´æ¥ç©ºè¾“å…¥ä¹Ÿè¡Œ
    $ renshe =  renpy.input("å†™ä¸Šäººè®¾",length=200)    
    $ web = web_base + "/identity?text=" + renshe + "&mapping=" + str(your_name)
    $ renshe = requests.get(web).text
    jump sense1

label sense1:
#è·å–å½“å‰é¡¹ç›®æ‰€åœ¨è·¯å¾„ï¼Œåˆ›å»ºå­˜å‚¨éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„
    $ current_work_dir = os.path.dirname(__file__)
    $ weight_path = os.path.join(current_work_dir, 'temp.ogg')
    $ weight_path = weight_path.replace("\\","/")
#äº¤äº’çš„ç¬¬ä¸€æ­¥
    $ your_text = renpy.input('',length=60)
#åˆæˆç½‘å€ç”¨æ¥å‘é€è¯·æ±‚(æœ¬æ¥åªæœ‰éœ€ä¼ å…¥æ–‡æœ¬å°±è¡Œäº†ï¼Œåæ¥å‚æ•°è¶Šä¼ è¶Šå¤š)
    $ webs = web_base + "/gpt?text="+ your_text  + "&speakers_name=" + str(spk_id) +"&api_key=" + str(open_api_key) + "&mapping=" + str(your_name) + "&noise_scale=" + str(noise_scale) + "&noise_scale_w=" + str(noise_scale_w) + "&spd=" + str(noise_scale_0)
#è¿™å°±æ˜¯å¦å¤–ä¸€ç§æ’å…¥pythonæŒ‡ä»¤çš„æ–¹æ³•äº†ï¼Œç”¨treadingå®ç°åŒæ­¥è¿è¡Œ
    python:
        def get_voice():
            res = requests.get(webs)
            music = res.content
            with open(weight_path, 'wb') as code:
                code.write(music)
            web2 = web_base + "/word?mapping=" + your_name
            answer = requests.get(web2).text
            global answer
#            os.system(weight_path)
        thread = threading.Thread(target=get_voice)
        thread.start()
#è¿™æ˜¯é€‰æ‹©ç•Œé¢ï¼Œå†³å®šæ˜¯å¦è¦remake
menu:
    "æŸ¥çœ‹å›å¤":
        jump reply
    "é‡æ–°è®¾å®š":
        jump setting0
#æœ€åçš„å±•ç¤ºé˜¶æ®µï¼Œå¯ä»¥è‡ªå·±æ·»åŠ åŠ¨ä½œï¼Œè¿™é‡Œé€‰æ‹©ç”¨voiceæ’­æ”¾å£°éŸ³è€Œä¸æ˜¯ç®€å•ç²—æš´çš„os
label reply:
    show Character1 motion2
    voice weight_path
    Setsuna '[answer]'
    show Character1 motion2
    jump sense1

```
